{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training Notebook\n\nThis notebook provides an example of how to train machine learning models using the AI/ML Project Template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport joblib\nimport yaml\n\n# Import project modules\nimport sys\nsys.path.append('../src')\n\nfrom data.preprocessing import preprocess_data\nfrom models.training import train_model\nfrom models.evaluation import evaluate_model\n\n# Load configuration\nwith open('../config/development.yaml', 'r') as f:\n    config = yaml.safe_load(f)\n\nprint('Configuration loaded successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preprocess data\n# Replace 'your_processed_data.csv' with the actual path to your processed data file\ndf = pd.read_csv('../data/processed/your_processed_data.csv')\n\n# Separate features and target\nX = df.drop('target_column', axis=1)  # Replace 'target_column' with your actual target column name\ny = df['target_column']\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f'Training set size: {X_train.shape}')\nprint(f'Test set size: {X_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize models\nmodels = {\n    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n    'Logistic Regression': LogisticRegression(random_state=42)\n}\n\n# Train and evaluate models\nresults = {}\n\nfor name, model in models.items():\n    print(f'\nTraining {name}...')\n    \n    # Train model\n    model.fit(X_train, y_train)\n    \n    # Make predictions\n    y_pred = model.predict(X_test)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    # Cross-validation\n    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n    \n    # Store results\n    results[name] = {\n        'model': model,\n        'accuracy': accuracy,\n        'cv_mean': cv_scores.mean(),\n        'cv_std': cv_scores.std()\n    }\n    \n    print(f'{name} Accuracy: {accuracy:.4f}')\n    print(f'{name} CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare model performance\nprint('\nModel Comparison:')\nprint('================')\n\nbest_model = None\nbest_accuracy = 0\n\nfor name, result in results.items():\n    print(f'{name}:')\n    print(f'  Accuracy: {result[\"accuracy\"]:.4f}')\n    print(f'  CV Score: {result[\"cv_mean\"]:.4f} (+/- {result[\"cv_std\"] * 2:.4f})')\n    \n    if result['accuracy'] > best_accuracy:\n        best_accuracy = result['accuracy']\n        best_model = result['model']\n        best_model_name = name\n\nprint(f'\nBest Model: {best_model_name} with accuracy {best_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed evaluation of the best model\nbest_y_pred = best_model.predict(X_test)\n\nprint(f'\nDetailed Evaluation for {best_model_name}:')\nprint('====================================')\n\nprint('\nClassification Report:')\nprint(classification_report(y_test, best_y_pred))\n\nprint('\nConfusion Matrix:')\nprint(confusion_matrix(y_test, best_y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance (for tree-based models)\nif hasattr(best_model, 'feature_importances_'):\n    feature_importance = pd.DataFrame({\n        'feature': X.columns,\n        'importance': best_model.feature_importances_\n    }).sort_values('importance', ascending=False)\n    \n    print('\nFeature Importance:')\n    print(feature_importance.head(10))\n    \n    # Plot feature importance\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=(10, 6))\n    plt.barh(feature_importance.head(10)['feature'], feature_importance.head(10)['importance'])\n    plt.xlabel('Importance')\n    plt.title('Top 10 Feature Importances')\n    plt.gca().invert_yaxis()\n    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model\nmodel_path = f'../models/{best_model_name.lower().replace(\" \", \"_\")}_model.pkl'\njoblib.dump(best_model, model_path)\n\nprint(f'\nBest model saved to: {model_path}')\n\n# Save results to a file\nresults_df = pd.DataFrame([\n    {\n        'model': name,\n        'accuracy': result['accuracy'],\n        'cv_mean': result['cv_mean'],\n        'cv_std': result['cv_std']\n    }\n    for name, result in results.items()\n])\n\nresults_df.to_csv('../models/training_results.csv', index=False)\nprint('Training results saved to: ../models/training_results.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter tuning example (optional)\nfrom sklearn.model_selection import GridSearchCV\n\nprint('\nPerforming hyperparameter tuning for Random Forest...')\n\n# Define parameter grid\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [None, 10, 20],\n    'min_samples_split': [2, 5, 10]\n}\n\n# Initialize GridSearchCV\ngrid_search = GridSearchCV(\n    RandomForestClassifier(random_state=42),\n    param_grid,\n    cv=5,\n    scoring='accuracy',\n    n_jobs=-1\n)\n\n# Fit GridSearchCV\ngrid_search.fit(X_train, y_train)\n\n# Get best parameters and score\nprint(f'Best parameters: {grid_search.best_params_}')\nprint(f'Best cross-validation score: {grid_search.best_score_:.4f}')\n\n# Evaluate best model\nbest_tuned_model = grid_search.best_estimator_\nbest_tuned_pred = best_tuned_model.predict(X_test)\ntuned_accuracy = accuracy_score(y_test, best_tuned_pred)\n\nprint(f'Tuned model test accuracy: {tuned_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\nModel training completed!')\nprint('=========================')\nprint(f'Best model: {best_model_name}')\nprint(f'Best accuracy: {best_accuracy:.4f}')\n\nif 'tuned_accuracy' in locals():\n    print(f'Tuned model accuracy: {tuned_accuracy:.4f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}